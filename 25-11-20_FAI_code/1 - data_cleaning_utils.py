#data_cleaning_utils.py      
## Funciones gen√©ricas de limpieza, filtros, helpers
# - Limpieza de CSV y verificaci√≥n (check_and_fix_csv)
# - Filtrado de d√≠as con huecos largos (filter_days_with_long_gaps)
# - Limpieza completa de GOES (clean_goes_data_full)
# - Gr√°ficas:
#       - Funnel plot (plot_cleaning_funnel)
#       - Comparaci√≥n con m√°scara (plot_with_mask_comparison)
#       - Comparaci√≥n entre DataFrames (plot_comparison_scatter)

from datetime import datetime, timedelta
import pandas as pd
import os
import matplotlib.pyplot as plt
import numpy as np
import re

# Funci√≥n: Verificar folder
def ensure_dir(path):
    """
    Verifica si una carpeta existe; si no, la crea.
    
    Parameters
    ----------
    path : str
        Ruta de la carpeta a verificar o crear.

    Returns
    -------
    str
        La ruta final de la carpeta.
    """
    if os.path.exists(path):
        print(f"‚ö†Ô∏è La carpeta ya exist√≠a: {path}")
    else:
        os.makedirs(path, exist_ok=True)
        print(f"üìÅ Carpeta creada: {path}")
    
    return path

# Funci√≥n: fix: column-datetime, resolution-1min, No-duplicate
def check_and_fix_csv(csv_path, output_dir, n, output_filename, time_col="Unnamed: 0"):
    """
    Checks and fixes a CSV file to ensure:
    - The time column is in datetime format
    - The time resolution is 1 minute
    - There are no duplicate timestamps
    Saves the cleaned file in the specified output directory.
    """
    
    print(f"\n=== Checking file: {csv_path} ===")
    
    # --- Load CSV ---
    try:
        df = pd.read_csv(csv_path)
    except Exception as e:
        print(f"‚ùå Error reading the file: {e}")
        return
    
    changes = []  # keep track of any corrections made
    
    # --- Verify time column ---
    if time_col not in df.columns:
        print(f"‚ùå The time column '{time_col}' does not exist in the CSV.")
        return
    
    # --- Convert to datetime ---
    # Remove decimals if present
    original_time_values = df[time_col].astype(str)
    if original_time_values.str.contains(r"\.").any():
        print("üßπ Decimal points detected in timestamps. Removing fractional seconds...")
        df[time_col] = original_time_values.str.split(".").str[0]
    else:
        print("‚úÖ No decimal points found in timestamps.")

    # Try to convert to datetime
    try:
        df[time_col] = pd.to_datetime(df[time_col], format="%Y-%m-%d %H:%M:%S", errors="coerce")
        if df[time_col].isna().any():
            print("‚ö†Ô∏è Some timestamps could not be parsed using the strict format. They were set to NaT.")
    except Exception as e:
        print(f"‚ö†Ô∏è Error while converting to datetime: {e}")
        print("üîÑ Retrying with automatic format detection...")
        df[time_col] = pd.to_datetime(df[time_col], errors="coerce")



    # Drop invalid (NaT) rows
    # --- Drop invalid (NaT) rows ---
    n_null = df[time_col].isna().sum()
    if n_null > 0:
        print(f"‚ö†Ô∏è Found {n_null} invalid or missing timestamps. Removing them...")
        changes.append(f"Removed {n_null} rows with invalid or missing timestamps.")
        df = df.dropna(subset=[time_col])
    else:
        print("‚úÖ No invalid or missing timestamps found.")

    # --- Check for duplicates ---
    duplicate_count = df.duplicated(subset=time_col).sum()
    if duplicate_count > 0:
        print(f"‚ö†Ô∏è Found {duplicate_count} duplicated timestamps. Keeping the first occurrence...")
        changes.append(f"Removed {duplicate_count} duplicate rows.")
        n_before = len(df)
        df = df.drop_duplicates(subset=time_col, keep="first")
        n_after = len(df)
        print(f"   ‚Üí Rows before: {n_before}, after: {n_after}")
    else:
        print("‚úÖ No duplicated timestamps found.")
    
    # --- Check time resolution ---
    df = df.sort_values(by=time_col)
    diffs = df[time_col].diff().dropna()
    freq_counts = diffs.value_counts()

    if not freq_counts.empty:
        most_common_freq = freq_counts.index[0]
        if most_common_freq.total_seconds() == 60:
            print("‚úÖ Main resolution: 1 minute")
        else:
            changes.append(f"Detected time step: {most_common_freq}.")
            print(f"‚ö†Ô∏è Main resolution is not 1 minute, detected: {most_common_freq}")
    else:
        print("‚ö†Ô∏è Could not determine time resolution (too few rows).")
        
    # --- Save cleaned CSV ---
    
    output_path = os.path.join(output_dir, output_filename)
    df.to_csv(output_path, index=False)
    
    # --- Final report ---
    print(f"\nFile saved to: {output_path}")
    if changes:
        print("üîß Changes made:")
        for c in changes:
            print(" - " + c)
    else:
        print("‚úÖ Data were already clean. No changes applied.")
    
    return df

# Funci√≥n: detectar huecos largos
def filter_days_with_long_gaps(df, output_dir, gap_minutes=20):
    """
    Detecta y elimina d√≠as que tengan >= gap_minutes consecutivos de datos faltantes en GOES (xrsa/xrsb).
    
    Parameters
    ----------
    df : pandas.DataFrame
        DataFrame con columnas 'date', 'xrsa', 'xrsb'.
    gap_minutes : int
        N√∫mero de registros consecutivos faltantes permitido antes de eliminar el d√≠a.
    
    Returns
    -------
    df_valid : DataFrame
        DataFrame filtrado sin los d√≠as con huecos largos.
    days_with_gaps : list
        Lista de d√≠as que fueron eliminados.
    new_n : int
        N√∫mero de d√≠as restantes despu√©s del filtro.
    """

    # --- Preparaci√≥n ---
    df = df.copy()
    df["date"] = pd.to_datetime(df["date"])
    df.replace("", pd.NA, inplace=True)
    df["day"] = df["date"].dt.date

    goes_cols = ["xrsa", "xrsb"]
    df["GOES_missing"] = df[goes_cols].isna().any(axis=1)

    # --- Funci√≥n interna ---
    def has_long_gap(group):
        missing = group.sort_values("date")["GOES_missing"].values
        count = 0
        for m in missing:
            if m:
                count += 1
                if count >= gap_minutes:
                    return True
            else:
                count = 0
        return False

    # --- Detectar d√≠as con huecos largos ---
    days_with_gaps = (
        df.groupby("day")
        .apply(lambda g: has_long_gap(g), include_groups=False)
    )

    days_with_gaps = days_with_gaps[days_with_gaps].index.tolist()

    # --- Filtrar d√≠as v√°lidos ---
    df_valid = df[~df["day"].isin(days_with_gaps)].copy()
    new_n = df_valid['day'].nunique()

    # --- Resumen ---
    print(f"üï≥Ô∏è D√≠as con huecos ‚â•{gap_minutes} min consecutivos en GOES:")
    print(f"\nüìÖ Total de d√≠as originales: {df['day'].nunique()}")
    print(f"‚ùå D√≠as eliminados: {len(days_with_gaps)}")
    print(f"‚úÖ D√≠as restantes: {new_n}")

    # --- Guardar archivos ---
    output_filename = f'df_full_{new_n}_cleaned.csv'
    output_path = os.path.join(output_dir, output_filename)
    df_valid.to_csv(output_path, index=False)

    # Guarda tambi√©n los d√≠as con huecos
    gaps_filename = f"days_with_{gap_minutes}min_gaps.csv"
    pd.Series(days_with_gaps, name=f"days_with_{gap_minutes}min_gaps").to_csv(
        os.path.join(output_dir, gaps_filename),
        index=False
    )

    print(f"\nüìÅ Archivo guardado GOES clean sin gaps: {output_path}\n")
    
    return df_valid, days_with_gaps, new_n

# Funci√≥n: filtrar negativos, ceros, NaN y T_Cor repetidos
def clean_goes_data_full(df, output_dir, GOES_graphics_dir, repeat_filter=1,
                         T_lower=1, T_upper=100, save_funnel=True):
    """
    Limpieza completa de datos GOES:
    1Ô∏è‚É£ Elimina negativos, ceros y NaN
    2Ô∏è‚É£ Filtra valores repetidos de T_cor
    3Ô∏è‚É£ Filtra outliers de T_cor seg√∫n l√≠mites f√≠sicos
    4Ô∏è‚É£ Genera gr√°fica tipo funnel y guarda CSV final (opcional)
    
    Parameters
    ----------
    df : pd.DataFrame
        DataFrame original con columnas 'xrsa', 'xrsb', 'xrsa_corr', 'xrsb_corr', 'T_cor', 'EM_cor', etc.
    output_dir : str
        Carpeta donde se guardar√° el CSV filtrado
    GOES_graphics_dir : str
        Carpeta donde se guardar√° la gr√°fica tipo funnel
    repeat_filter : int
        N√∫mero m√°ximo de repeticiones de T_cor permitidas (mayor ser√° eliminado)
    T_lower : float
        L√≠mite inferior f√≠sico para T_cor (MK)
    T_upper : float
        L√≠mite superior f√≠sico para T_cor (MK)
    save_funnel : bool
        Si True, guarda la gr√°fica tipo funnel
    
    Returns
    -------
    dict
        {
            "df_cleaned": df_no_nan,      # filtrado por negativos, ceros y NaN
            "df_final": df_Tcor_valid,    # filtrado completo incluyendo repetidos y outliers
            "steps_counts": counts_list,  # para gr√°fica funnel
            "steps_labels": steps_list    # labels de los pasos
        }
    """
    df = df.copy()
    
    # --- Convertir fechas y preparar ---
    df["date"] = pd.to_datetime(df["date"])
    df.replace("", pd.NA, inplace=True)
    print(f"\n1. Eliminando negativos:")
    # --- Eliminar negativos ---
    num_cols = df.select_dtypes(include='number').columns
    df = df[(df[num_cols] >= 0).all(axis=1)]

    print(f"2. Eliminando ceros:")
    # --- Eliminar ceros ---
    zero_cols = ['xrsa', 'xrsb', 'xrsa_corr', 'xrsb_corr']
    df = df[(df[zero_cols] != 0).all(axis=1)]
    
    print(f"3. Eliminando NaN:")
    # --- Eliminar NaN ---
    nan_cols = [col for col in df.columns if col not in ['date', 'observatory']]
    df_no_nan = df.dropna(subset=nan_cols)
    
    # --- Guardar df limpio antes de T_cor (para gr√°ficas con mask) ---
    df_cleaned = df_no_nan.copy()
    
    print(f"4. Eliminando repetidos de T_cor:")
    # --- Filtrar valores repetidos de T_cor ---
    T_counts = df_no_nan['T_cor'].value_counts()
    repeated_T_values = T_counts[T_counts > repeat_filter].index
    df_no_repeated = df_no_nan[~df_no_nan['T_cor'].isin(repeated_T_values)]
    
    print(f"5. Eliminando outliers T_cor seg√∫n l√≠mites f√≠sicos:")
    # --- Filtrar outliers T_cor seg√∫n l√≠mites f√≠sicos ---
    df_Tcor_valid = df_no_repeated[
        (df_no_repeated["T_cor"] >= T_lower) &
        (df_no_repeated["T_cor"] <= T_upper)].copy()
    # por confirmar el n√∫mero de d√≠as
    df_Tcor_valid["day"] = df_Tcor_valid["date"].dt.date

    new_n = df_Tcor_valid['day'].nunique()
    
    # --- Guardar CSV final ---
    final_filename = f"df_full_{new_n}_valid.csv"
    os.makedirs(output_dir, exist_ok=True)
    output_path = os.path.join(output_dir, final_filename)
    df_Tcor_valid.to_csv(output_path, index=False)
    print(f"\nüìÅ Archivo guardado GOES sin gaps,-,0,NaN,Trep,outliers: {output_path}\n")

    # --- Preparar info para funnel plot ---
    steps_list = [
        'Total rows',
        'After removing negatives',
        'After removing zeros',
        'After removing NaN',
        'After removing repeated T_cor',
        'After removing T_cor outliers'
    ]
    counts_list = [
        len(df),                       # Total rows
        len(df),                       # Despu√©s de negativos
        len(df[df[zero_cols].gt(0).all(axis=1)]),  # Despu√©s de ceros
        len(df_no_nan),                 # Despu√©s de NaN
        len(df_no_repeated),            # Despu√©s de repetidos
        len(df_Tcor_valid)              # Despu√©s de outliers
    ]
    
    # --- Llamar a plot_cleaning_funnel si save_funnel=True ---
    if save_funnel:
        plot_cleaning_funnel(steps=steps_list,
                            counts=counts_list,
                            df_full_clean_len=len(df),
                            GOES_graphics_dir=GOES_graphics_dir,
                            filename="funnel_cleaning.png")
        

    return {
        "df_cleaned": df_cleaned,
        "df_final": df_Tcor_valid,
        "steps_counts": counts_list,
        "steps_labels": steps_list
    }


# Gr√°fica: Cleaning funnel plot
def plot_cleaning_funnel(steps, counts,
                         df_full_clean_len,
                         GOES_graphics_dir, 
                         filename="data_cleaning_funnel.png"):
    
    colors = ['lightblue', 'lightcoral', 'khaki', 'lightgreen', 'orchid', 'salmon']

    plt.figure(figsize=(10, 5))
    bars = plt.barh(range(len(steps)), counts, color=colors[:len(steps)], edgecolor='black')

    plt.yticks(range(len(steps)), steps)
    plt.xlabel('Number of rows')
    plt.title('Data Cleaning Funnel: GOES')
    plt.gca().invert_yaxis()
    plt.grid(axis='x', alpha=0.3, linestyle='--')

    # A√±adir n√∫meros y porcentajes
    percentages = [count / df_full_clean_len * 100 for count in counts]
    for i, (bar, count, percent) in enumerate(zip(bars, counts, percentages)):
        width = bar.get_width()
        y_pos = bar.get_y() + bar.get_height() / 2
        width_ratio = width / max(counts)
        if width_ratio > 0.25:
            plt.text(width / 2, y_pos, f"{count:,}\n({percent:.1f}%)", 
                     va='center', ha='center', fontsize=10)
        else:
            label_x = width + (max(counts) * 0.02)
            plt.text(label_x, y_pos, f"{count:,}\n({percent:.1f}%)", 
                     va='center', ha='left', fontsize=10)

    plt.xlim(0, max(counts)*1.1)
    plt.tight_layout()

    plot_path = os.path.join(GOES_graphics_dir, filename)
    plt.savefig(plot_path, dpi=150)
    plt.close()
    print(f"üìÅ Cleaning funnel plot saved to: {plot_path}")

# Gr√°fica: Mascara de revisi√≥n
def plot_with_mask_comparison(
        df, mask, x_cols, y_cols, titles=None,
        mask_labels=None, colors=None, x_scales=None, y_scales=None,
        x_limits=None, y_limits=None, figsize=(12, 6), alpha=0.5, s=10,
        save=False, save_dir=None, filename="mask_comparison.png"):
    """
    Scatter plots highlighting masked vs non-masked data.
    """

    n_plots = len(x_cols)

    # Defaults
    if mask_labels is None:
        mask_labels = ['Masked data', 'Non-masked data']
    if colors is None:
        colors = ['red', 'blue']
    if titles is None:
        titles = [f'{y} vs {x}' for x, y in zip(x_cols, y_cols)]
    if x_scales is None:
        x_scales = ['linear'] * n_plots
    if y_scales is None:
        y_scales = ['linear'] * n_plots

    df_masked = df[mask]
    df_non_masked = df[~mask]

    print(f"Masked data: {len(df_masked)} rows")
    print(f"Non-masked data: {len(df_non_masked)} rows")

    fig, axes = plt.subplots(1, n_plots, figsize=figsize)
    if n_plots == 1:
        axes = [axes]

    for i, (x_col, y_col) in enumerate(zip(x_cols, y_cols)):
        ax = axes[i]

        ax.scatter(df_non_masked[x_col], df_non_masked[y_col], 
                   s=s, alpha=alpha, color=colors[1], 
                   label=mask_labels[1])

        ax.scatter(df_masked[x_col], df_masked[y_col], 
                   s=s, alpha=alpha, color=colors[0], 
                   label=mask_labels[0])

        ax.set_xscale(x_scales[i])
        ax.set_yscale(y_scales[i])

        if x_limits and x_limits[i]:
            ax.set_xlim(x_limits[i])
        if y_limits and y_limits[i]:
            ax.set_ylim(y_limits[i])

        ax.set_xlabel(x_col, fontsize=12)
        ax.set_ylabel(y_col, fontsize=12)
        ax.set_title(titles[i], fontsize=14)
        ax.grid(True, linestyle='--', alpha=0.5)
        ax.legend()

    plt.tight_layout()

    # Save or show
    if save:
        if save_dir is None:
            raise ValueError("save_dir must be provided when save=True.")
        plt.savefig(f"{save_dir}/{filename}", dpi=150)
        print(f"üìÅ Saved: {save_dir}/{filename}")
    else:
        plt.show()

    plt.close()

    return fig, axes

# Gr√°fica: comparaci√≥n datos con y sin filtro
def plot_comparison_scatter(
        df_list, x_cols, y_cols, titles=None,
        colors=None, x_scales=None, y_scales=None,
        x_limits=None, y_limits=None,
        figsize=(10, 9), alpha=0.5, s=10,
        save=False, save_dir=None, filename="scatter_comparison.png"):
    """
    Grid of scatter plots comparing multiple DataFrames.
    """

    n_dfs = len(df_list)
    n_plots = len(x_cols)

    if titles is None:
        titles = [f'DataFrame {i+1}' for i in range(n_dfs)]
    if colors is None:
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
    if x_scales is None:
        x_scales = ['linear'] * n_plots
    if y_scales is None:
        y_scales = ['linear'] * n_plots

    fig, axes = plt.subplots(n_dfs, n_plots, figsize=figsize)

    # Ensure 2D axes
    if n_dfs == 1:
        axes = axes.reshape(1, -1)
    if n_plots == 1:
        axes = axes.reshape(-1, 1)

    for i, df in enumerate(df_list):
        for j in range(n_plots):
            ax = axes[i, j]

            ax.scatter(df[x_cols[j]], df[y_cols[j]],
                       s=s, alpha=alpha, color=colors[j],
                       label=f'{x_cols[j]} vs {y_cols[j]}')

            ax.set_xscale(x_scales[j])
            ax.set_yscale(y_scales[j])

            if x_limits and x_limits[j]:
                ax.set_xlim(x_limits[j])
            if y_limits and y_limits[j]:
                ax.set_ylim(y_limits[j])

            ax.set_xlabel(x_cols[j], fontsize=12)
            ax.set_ylabel(y_cols[j], fontsize=12)
            ax.set_title(f'{titles[i]}: {x_cols[j]} vs {y_cols[j]}', fontsize=14)
            ax.grid(True, linestyle='--', alpha=0.5)
            ax.legend()

    plt.tight_layout()

    # Save or show
    if save:
        if save_dir is None:
            raise ValueError("save_dir must be provided when save=True.")
        plt.savefig(f"{save_dir}/{filename}", dpi=150)
        print(f"üìÅ Saved: {save_dir}/{filename}")
    else:
        plt.show()

    plt.close()

    return fig, axes

# Gr√°fica: resumen filtros flares
def plot_funnel(steps, counts, output_dir=None, filename="funnel_cleaning.png"):

    fig, ax = plt.subplots(figsize=(8, 5))
    ax.plot(counts, steps, marker='o', color='blue')
    ax.set_xlabel("N√∫mero de flares v√°lidos")
    ax.set_ylabel("Paso de limpieza")
    ax.set_title("Funnel plot limpieza de flares")
    ax.grid(True, linestyle='--', alpha=0.5)
    plt.gca().invert_yaxis()  # Paso inicial arriba
    
    if output_dir is not None:
        os.makedirs(output_dir, exist_ok=True)
        path = os.path.join(output_dir, filename)
        plt.savefig(path, dpi=150, bbox_inches='tight')
        print(f"üìä Funnel plot guardado: {path}")
    
    plt.close()

def save_cleaning_log(steps, counts, output_dir, filename="cleaning_log.txt"):
    import os
    os.makedirs(output_dir, exist_ok=True)
    path = os.path.join(output_dir, filename)
    
    with open(path, "w") as f:
        f.write("Limpieza de flares - resumen por pasos\n")
        f.write("="*40 + "\n")
        for step, count in zip(steps, counts):
            f.write(f"{step:<35} : {count}\n")
        f.write("="*40 + "\n")
        f.write(f"Total flares finales: {counts[-1]}\n")
    
    print(f"üìù Log de limpieza guardado: {path}")

# crear columnas de tiempos
def calculate_flare_durations(df):
    """
    Convierte las columnas de tiempo a datetime, calcula duraciones en minutos
    y reordena columnas, manteniendo todas las columnas originales.

    Par√°metros
    ----------
    df : pd.DataFrame
        DataFrame con columnas 'StartTime', 'PeakTime', 'EndTime' y otras.

    Retorna
    -------
    pd.DataFrame
        DataFrame con nuevas columnas: 'StartPeak', 'StartEnd', 'PeakEnd',
        y con las columnas de tiempo/duraci√≥n al principio.
    """
    df = df.copy()

    # --- Convertir a datetime ---
    df['StartTime'] = pd.to_datetime(df['StartTime'], errors='coerce')
    df['PeakTime']  = pd.to_datetime(df['PeakTime'], errors='coerce')
    df['EndTime']   = pd.to_datetime(df['EndTime'], errors='coerce')

    # --- Calcular duraciones en minutos ---
    df['StartPeak'] = (df['PeakTime'] - df['StartTime']).dt.total_seconds() / 60
    df['StartEnd']  = (df['EndTime'] - df['StartTime']).dt.total_seconds() / 60
    df['PeakEnd']   = (df['EndTime'] - df['PeakTime']).dt.total_seconds() / 60

    # --- Reordenar columnas ---
    time_cols = ['StartTime', 'PeakTime', 'EndTime', 'StartPeak', 'StartEnd', 'PeakEnd', 'Class', 'ClassLetter', 'ClassNumber', 'ClassGroup', 'NOAA_Class']
    other_cols = [c for c in df.columns if c not in time_cols]
    df = df[time_cols + other_cols]

    print(f"‚úî Columnas de duraci√≥n calculadas y DataFrame reordenado ({len(df)} flares).")

    return df

# Funci√≥n: solo limpiar y arreglar clase
def clean_flare_by_class(df_flares, output_dir=None, output_name=None, group_subclasses=True, funnel_dir=None):
    df = df_flares.copy()
    counts = [len(df)]
    steps = ["Original"]
    
    # Validar clase
    df["Class"] = df["Class"].astype(str)
    pattern = r"^[A-Z]\d+(\.\d+)?$"
    df = df[df["Class"].str.match(pattern, na=False)]
    counts.append(len(df))
    steps.append("Clase v√°lida (regex)")
    
    # Extraer letra y n√∫mero
    df["ClassLetter"] = df["Class"].str[0]
    df["ClassNumber"] = df["Class"].str[1:].astype(float)
    
    # Agrupar subclases
    group_ranges = {
        "A": [(1, 4.9), (5, 9.9)],
        "B": [(1, 4.9), (5, 9.9)],
        "C": [(1, 4.9), (5, 9.9)],
        "M": [(1, 4.9), (5, 9.9)],
        "X": [(1, 4.9), (5, 1000)],
    }
    def assign_group(cls):
        letter = cls[0]
        number = float(cls[1:])
        for low, high in group_ranges.get(letter, []):
            if low <= number <= high:
                return f"{letter}{low}-{high if high < 1000 else '+'}"
        return cls
    if group_subclasses:
        df["ClassGroup"] = df["Class"].apply(assign_group)
    else:
        df["ClassGroup"] = df["ClassLetter"]
    
    print(f"‚úî Limpieza por clase completa. {len(df)} flares v√°lidos.")
    
    # Guardar CSV
    if output_dir and output_name:
        path = os.path.join(output_dir, output_name)
        df.to_csv(path, index=False)
        print(f"üìÅ Archivo guardado: {path}")
    
    # Funnel plot
    if funnel_dir:
        plot_funnel(steps, counts, output_dir=funnel_dir, filename="funnel_class.png")
        save_cleaning_log(steps, counts, output_dir=funnel_dir, filename="log_class.txt")
    
    return df

# Funci√≥n: limpieza por duraci√≥n
def clean_flares_by_duration(df, output_dir=None, output_name=None, funnel_dir=None):
    """
    Limpieza basada en duraci√≥n del flare:
    - Validar Start ‚â§ Peak ‚â§ End
    - Validar StartPeak y PeakEnd ‚â§ 720
    - Filtro especial de duraci√≥n seg√∫n clase
    - Crear Flare_ID
    """
    df = df.copy()
    counts = [len(df)]
    steps = ["Original"]
    
    letters = df['ClassLetter']
    
    # Duraci√≥n seg√∫n clase
    duration_by_class = ((letters < 'C') & (df['StartEnd'] <= 180)) | ((letters >= 'C') & (df['StartEnd'] <= 720))
    df = df[duration_by_class]
    counts.append(len(df))
    steps.append("Duraci√≥n seg√∫n clase")
    
    # Orden correcto
    valid_order = (df['StartTime'] <= df['PeakTime']) & (df['PeakTime'] <= df['EndTime'])
    df = df[valid_order]
    counts.append(len(df))
    steps.append("Orden Start ‚â§ Peak ‚â§ End")
    
    # Duraciones razonables
    valid_duration = (df['StartPeak'] <= 720) & (df['PeakEnd'] <= 720)
    df = df[valid_duration]
    counts.append(len(df))
    steps.append("StartPeak & PeakEnd ‚â§ 720")
    
    # Crear Flare_ID
    df["Flare_ID"] = df["PeakTime"].dt.strftime("%Y%m%d%H%M") + "_" + df["Class"]

    # --- Reordenar columnas ---
    time_cols = ['Flare_ID', 'StartTime']
    other_cols = [c for c in df.columns if c not in time_cols]
    df = df[time_cols + other_cols]

    counts.append(len(df))
    steps.append("Creaci√≥n Flare_ID")
    
    print(f"‚úî Limpieza por duraci√≥n completa. {len(df)} flares v√°lidos de {counts[0]}.")
    
    # Guardar CSV
    if output_dir and output_name:
        path = os.path.join(output_dir, output_name)
        df.to_csv(path, index=False)
        print(f"üìÅ Archivo guardado: {path}")
    
    # Funnel plot y log
    if funnel_dir:
        plot_funnel(steps, counts, output_dir=funnel_dir, filename="funnel_duration.png")
        save_cleaning_log(steps, counts, output_dir=funnel_dir, filename="log_duration.txt")
    
    return df

# Funci√≥n: filtro de flares por d√≠as de datos GOES v√°lidos
def filter_flares_by_goes_dates(df_flares, df_goes, output_dir=None, output_name=None):
    """
    Filtra flares para quedarse solo con aquellos cuyas fechas coinciden
    con las fechas disponibles en df_goes.

    Parameters
    ----------
    df_flares : pd.DataFrame
        DataFrame de flares limpios, debe contener columna 'PeakTime'.
    df_goes : pd.DataFrame
        DataFrame GOES con columna 'date'.
    output_dir : str, optional
        Carpeta donde guardar el CSV final.
    output_name : str, optional
        Nombre del archivo CSV a guardar.

    Returns
    -------
    pd.DataFrame
        DataFrame de flares filtrados por fechas de GOES.
    """
    df = df_flares.copy()

    # Convertir a datetime para evitar warnings
    df["PeakTime"] = pd.to_datetime(df["PeakTime"], errors="coerce")
    df_goes["date"] = pd.to_datetime(df_goes["date"], errors="coerce")

    # Contar antes del filtro
    n_before = len(df)

    # Filtrar flares seg√∫n fechas disponibles en GOES
    df = df[df["PeakTime"].isin(df_goes["date"])]

    # Contar despu√©s del filtro
    n_after = len(df)

    # Mostrar resumen
    print(f"Flares antes del filtro: {n_before}")
    print(f"Flares despu√©s del filtro: {n_after}")
    print(f"Flares eliminados: {n_before - n_after}")

    # Guardar CSV si se especifica
    if output_dir and output_name:
        os.makedirs(output_dir, exist_ok=True)
        path = os.path.join(output_dir, output_name)
        df.to_csv(path, index=False)
        print(f"üìÅ Archivo filtrado guardado: {path}")

    return df

# Gr√°fica: Histograma de tiempos por clase de flare
def plot_flare_times_histograms(df, class_column="ClassLetter", class_filter=None, graphics_dir="."):
    """
    Genera histogramas de tiempos (StartPeak, PeakEnd, StartEnd) para los flares filtrados por clase.
    
    Par√°metros:
        df: DataFrame con los flares.
        class_column: columna a usar para filtrar la clase ('ClassLetter' o 'ClassGroup').
        class_filter: valor de la clase a filtrar, e.g. 'C', 'M', 'C1-4.9'. Si es None, usa todos.
        graphics_dir: carpeta donde guardar la figura.
    """

    # Filtrar DataFrame por clase si se indica
    if class_filter is not None:
        df_plot = df[df[class_column] == class_filter]
        title_suffix = f"Class {class_filter}"
        output_name = f"Histogram_Flares_Times_{class_filter}.png"
    else:
        df_plot = df
        title_suffix = "All Classes"
        output_name = f"Histogram_Flares_Times_All.png"

    if df_plot.empty:
        print(f"No flares found for {title_suffix}.")
        return

    # Crear la figura con 3 subplots
    plt.figure(figsize=(12,4))
    time_cols = ['StartPeak', 'PeakEnd', 'StartEnd']

    for i, col in enumerate(time_cols, 1):
        plt.subplot(1, 3, i)
        plt.hist(df_plot[col], bins=20, color='skyblue', edgecolor='black')
        plt.title(f"{col} ({title_suffix})")
        plt.xlabel('Minutes')
        plt.ylabel('Number of Flares')

    plt.tight_layout()

    # Guardar figura
    output_path = os.path.join(graphics_dir, output_name)
    plt.savefig(output_path, dpi=300, bbox_inches="tight")
    print(f"\nFile saved to: {output_path}")

    plt.close()

# Gr√°fica: Histograma de flares por clases
def plot_flare_distribution(df, column="ClassGroup", color_mode="palette:viridis", graphics_dir="."):
    """
    Genera una gr√°fica de distribuci√≥n de clases de flares (conteo y porcentaje)
    usando la columna especificada (por defecto 'ClassGroup' o 'ClassLetter').
    """

    if column not in df.columns:
        raise ValueError(f"El DataFrame debe contener la columna '{column}'.")

    # -------------------------------
    # Conteos y porcentajes
    # -------------------------------
    counts = df[column].value_counts().sort_index()
    total_flares = counts.sum()
    percentages = (counts / total_flares * 100).round(1)

    # -------------------------------
    # Imprimir estad√≠sticas
    # -------------------------------
    print(f"\nStatistics for {column}:")
    print(f"{'Class':<10} {'Count':>8} {'Percentage (%)':>15}")
    for cls, cnt, pct in zip(counts.index, counts.values, percentages.values):
        print(f"{cls:<10} {cnt:>8} {pct:>15.1f}")
    print(f"{'Total':<10} {total_flares:>8} {percentages.sum():>15.1f}\n")

    classes = counts.index.tolist()
    values = counts.values.tolist()
    n_bars = len(classes)

    # -------------------------------
    # Colores
    # -------------------------------
    if color_mode.startswith("palette:"):
        cmap_name = color_mode.split(":", 1)[1]
        cmap = plt.cm.get_cmap(cmap_name, n_bars)
        colors = [cmap(i) for i in range(n_bars)]
    elif color_mode.startswith("single:"):
        single = color_mode.split(":", 1)[1]
        colors = [single] * n_bars
    else:
        colors = ["skyblue"] * n_bars

    # -------------------------------
    # Layout
    # -------------------------------
    chart_width = max(8, n_bars * 1.2)
    chart_height = 6
    fontsize = 8
    item_width = 0.25 * fontsize
    usable_width = chart_width * 0.9
    max_cols = int(usable_width / item_width)
    #ncol = min(n_bars, max_cols)
    ncol = 4
    n_rows = int(np.ceil(n_bars / ncol))
    legend_height_ratio = max(0.55, 0.55 * n_rows)

    plt.rcParams.update({
        "axes.titlesize": 16,
        "axes.labelsize": 15,
        "xtick.labelsize": 14,
        "ytick.labelsize": 15,
        "legend.fontsize": 14
    })

    fig = plt.figure(figsize=(chart_width, chart_height))
    gs = fig.add_gridspec(2, 1, height_ratios=[6, legend_height_ratio], hspace=0.5)

    # -------------------------------
    # Gr√°fico principal
    # -------------------------------
    ax = fig.add_subplot(gs[0])
    bars = ax.bar(range(n_bars), values, color=colors, edgecolor="black", width=0.9)

    ax.set_xlim(-0.5, n_bars - 0.5)
    ax.set_xticks(range(n_bars))
    ax.set_xticklabels(classes, rotation=0, ha="center")

    y_max = max(values)
    ax.set_ylim(0, y_max * 1.15)

    # Etiquetas de porcentaje sobre barras
    for bar, pct in zip(bars, percentages):
        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(values)*0.01,
                f"{pct:.1f}%", ha="center", va="bottom", fontsize=14)

    ax.set_ylabel("Number of flares")
    ax.set_xlabel("Flare Class")
    ax.set_title(f"Distribution of Solar Flares by {column}", pad=20)

    ax.text(0.98, 0.95, f"Total flares: {total_flares}",
            transform=ax.transAxes, ha='right', va='top', fontsize=12,
            bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.3'))

    # -------------------------------
    # Leyenda inferior
    # ------------------------
    ax_leg = fig.add_subplot(gs[1])
    ax_leg.axis("off")

    legend_labels = [f"{cls} (n={counts[cls]})" for cls in classes]
    handles = [plt.Line2D([], [], marker="s", markersize=8, linestyle="",
                          color=colors[i], label=legend_labels[i])
               for i in range(n_bars)]

    ax_leg.legend(handles=handles,
                  loc="center",
                  ncol=ncol,
                  frameon=False,
                  title=f"Number of flares per {column}:",
                  title_fontsize=15)

    # Guardar figura
    output_name = f"flare_distribution_{column}.png"
    output_path = os.path.join(graphics_dir, output_name)
    plt.savefig(output_path, dpi=300, bbox_inches="tight")
    print(f"\nFile saved to: {output_path}")

    plt.close()

# Funci√≥n: Filtro de Flares por clases
def filter_flares_by_class(df_flares, include_classes=None, exclude_classes=None, output_dir=None, output_name=None):
    """
    Filtra flares seg√∫n la letra de la clase o grupo.

    Parameters
    ----------
    df_flares : pd.DataFrame
        DataFrame de flares, debe contener 'ClassLetter' o 'ClassGroup'.
    include_classes : list of str, optional
        Lista de letras o grupos a incluir (p. ej. ['C','M','X']). Si se especifica,
        solo se mantienen estas clases.
    exclude_classes : list of str, optional
        Lista de letras o grupos a excluir (p. ej. ['A','B']). Si se especifica,
        se eliminan estas clases.
    output_dir : str, optional
        Carpeta donde guardar CSV filtrado.
    output_name : str, optional
        Nombre del CSV filtrado.

    Returns
    -------
    pd.DataFrame
        DataFrame filtrado.
    """
    df = df_flares.copy()

    # Prioridad: include_classes
    if include_classes is not None:
        df = df[df['ClassLetter'].isin(include_classes)]
    elif exclude_classes is not None:
        df = df[~df['ClassLetter'].isin(exclude_classes)]

    print(f"Flares despu√©s del filtro por clase: {len(df)} de {len(df_flares)}")

    # Guardar CSV si se indica
    if output_dir and output_name:
        os.makedirs(output_dir, exist_ok=True)
        path = os.path.join(output_dir, output_name)
        df.to_csv(path, index=False)
        print(f"üìÅ Archivo filtrado por clase guardado: {path}")

    return df
